###############################################################################
# Example Metadata Processor Config
###############################################################################

# Indicate what stage of the pipeline to run
pipeline:
  stage: metadata_processor

# I/O settings
# These settings work for the default AWS setup.
# The s3 buckets nitelite.metadata, nitelite.images, nitelite.referenced-images, and
# nitelite.pipeline-output are available to the pipeline inside /data/input.
# You can pull data from any of these simply by using the path relative to the bucket.
# See below for examples.
io_manager:
  # Specifies the input data
  input_dir: /data/input
  input_description:
    # Metadata files. This is the path relative to the input_dir.
    img_log: nitelite.metadata/220513-FH135/image.log
    imu_log: nitelite.metadata/220513-FH135/PresIMULog.csv
    gps_log: nitelite.metadata/220513-FH135/GPSLog.csv
    # Images without georeferencing. Needed for the metadata processor.
    images:
      # Relative to input_dir
      directory: nitelite.images/220513-FH135
      # Only files with these extensions will be considered.
      pattern: '\.(raw|tif|tiff)$'
  # Where the output files will be saved
  output_dir: /data/output/metadata
  output_description:
    metadata: combined_metadata.csv
    used_config: used-config.yaml
  # If the output directory already exists then a new directory is created
  # with a new ID attached.
  file_exists: overwrite

# Coordinate reference-system employed
crs:
  projparams: 'EPSG:3857' # The coordinate system used for google maps, this is a pretty good cartesian standard.

random_state: 
  seed: 159234
