{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'n_col_metadata': 50, # FH135 has 46 columns\n",
    "    'n_images': 3e4, # FH135 has 33783 images\n",
    "    'raw_to_tiff_ratio': 5,\n",
    "    'raw_image_size': 4.4e-3,\n",
    "    'tiff_image_size': 13e-3,\n",
    "    'n_referenced_images': 2e4,\n",
    "    'default_byte_size': 4,\n",
    "    'units': ('GB', 1024**3),\n",
    "    'disk_to_ram_ratio': 10, # Conservative numbers are higher\n",
    "    'n_flights': 20, # Currently there are six flights\n",
    "    'transfer_speed': 1e-2, # In GB/s.\n",
    "    'processing_speed': 5e-3, # In GB/s. This is probably a conservative estimate.\n",
    "    'n_full_metadata_queries_per_week': 50, # Should be conservative again\n",
    "    'n_full_image_queries_per_week': 1,\n",
    "    'minimum_processing_time': 60., # Assume no query uses less than this time in seconds\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Far Horizons Needs\n",
    "\n",
    "* Reference as many of the images as possible\n",
    "* Combine referenced images into a cohesive map\n",
    "* Give users control over how the images to make the map are selected\n",
    "* Give users control over how pixel values are calculated\n",
    "* Select all images within a given distance of a coordinate\n",
    "* Do the above for each flight\n",
    "* Maximize accessibility, maintainability, and editability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Needs\n",
    "\n",
    "* Retrieve reliable pixel values for within a given distance of a coordinate\n",
    "* Retrieve and visualize a map\n",
    "* Select different maps for different times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per flight reqs\n",
    "n_tiff = config['n_images'] / (1. + config['raw_to_tiff_ratio'])\n",
    "n_raw = config['n_images'] - n_tiff\n",
    "images_volume = config['tiff_image_size'] * n_tiff + \\\n",
    "    config['raw_image_size'] * n_raw\n",
    "images_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_image_volume = images_volume * config['n_flights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total metadata cpu usage assuming every query retrieves all the metadata\n",
    "image_time_estimate = (\n",
    "    (\n",
    "        # Time to process all the metadata\n",
    "        total_image_volume\n",
    "        / config['transfer_speed']\n",
    "    )\n",
    "    * config['n_full_image_queries_per_week']\n",
    "    / 3600. # Convert seconds to hours\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per flight reqs\n",
    "row_size_bytes = config['n_col_metadata'] * config['default_byte_size']\n",
    "table_size = (\n",
    "    row_size_bytes * config['n_referenced_images']\n",
    "    / config['units'][1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Across all flights\n",
    "total_metadata_volume = table_size * config['n_flights']\n",
    "metadata_ram = total_metadata_volume * config['disk_to_ram_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total metadata cpu usage assuming every query retrieves all the metadata\n",
    "metadata_time_estimate = (\n",
    "    (\n",
    "        # Time to process all the metadata\n",
    "        total_metadata_volume\n",
    "        / config['processing_speed']\n",
    "        + config['minimum_processing_time']\n",
    "    )\n",
    "    * config['n_full_metadata_queries_per_week']\n",
    "    / 3600. # Convert seconds to hours\n",
    ")\n",
    "n_writes_metadata = (\n",
    "    config['n_full_metadata_queries_per_week'] * config['n_referenced_images']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size per row: 0.2 KB\n",
      "Number of writes per week: 1e+06\n",
      "Required volume for images: 3.5e+03 GB\n",
      "Images usage estimate: 97.2 hrs/week\n",
      "\n",
      "Required volume for metadata: 0.075 GB\n",
      "Required RAM for metadata: 0.75 GB\n",
      "Metadata usage estimate: 1 hrs/week\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f'''\n",
    "Size per row: {row_size_bytes/1000:.2g} KB\n",
    "Number of writes per week: {n_writes_metadata:.2g}\n",
    "Required volume for images: {total_image_volume:.2g} {config['units'][0]}\n",
    "Images usage estimate: {image_time_estimate:.3g} hrs/week\n",
    "\n",
    "Required volume for metadata: {total_metadata_volume:.2g} {config['units'][0]}\n",
    "Required RAM for metadata: {metadata_ram:.2g} {config['units'][0]}\n",
    "Metadata usage estimate: {metadata_time_estimate:.2g} hrs/week\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Storage\n",
    "\n",
    "All solutions will require a way for unauthenticated users to access the data.\n",
    "[This guide](https://docs.aws.amazon.com/lambda/latest/operatorguide/public-endpoints.html) addresses a few possibilities, including using [lambda](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-lambda-tutorial.html) or a website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon RDS with Proxy\n",
    "\n",
    "In this solution the DB lives on Amazon RDS.\n",
    "The DB is stopped for most of the time, but is turned on when a request is made.\n",
    "\n",
    "Notes:\n",
    "- There are ways to automate the starting and stopping of the DB instance ([see here](https://aws.amazon.com/blogs/database/schedule-amazon-rds-stop-and-start-using-aws-lambda/))\n",
    "- Due to the small size of the DB, most of the cost will be in the proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon Dynamo DB\n",
    "\n",
    "In this solution the DB lives on Amazon Dynamo DB, and users query it.\n",
    "\n",
    "Notes:\n",
    "- Most operations we perform will be batch operations (25 items/operation max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3\n",
    "\n",
    "In this solution the data is stored on S3, and the full metadata dataset\n",
    "is downloaded everytime it's used. This is feasible because the full metadata\n",
    "dataset is anticipated to be <0.1 GB.\n",
    "\n",
    "Notes:\n",
    "- S3 Object Lambda could feasibly be used to filter a selection.\n",
    "- We might just want to store the data as a csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21899/3613613674.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  estimates = pd.read_csv('./NITELite_estimate.csv', header=5, skipfooter=2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group hierarchy</th>\n",
       "      <th>Region</th>\n",
       "      <th>Description</th>\n",
       "      <th>Service</th>\n",
       "      <th>Upfront</th>\n",
       "      <th>Monthly</th>\n",
       "      <th>First 12 months total</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Status</th>\n",
       "      <th>Configuration summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>DynamoDB:metadata</td>\n",
       "      <td>DynamoDB on-demand capacity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.1300</td>\n",
       "      <td>157.56</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Table class (Standard), Average item size (all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>DynamoDB:metadata</td>\n",
       "      <td>DynamoDB Backup and restore</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>10.80</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On-demand backup data storage (2 GB), Table da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>DynamoDB:metadata</td>\n",
       "      <td>DynamoDB Data export to Amazon S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>4.80</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full export to Amazon S3 (2 GB), Incremental e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>DynamoDB:metadata</td>\n",
       "      <td>DynamoDB Data Import from Amazon S3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>3.60</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uncompressed source file size for Import from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>RDS:metadata</td>\n",
       "      <td>Amazon RDS for PostgreSQL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.2325</td>\n",
       "      <td>278.79</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storage volume (General Purpose SSD (gp2)), St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>S3:metadata</td>\n",
       "      <td>S3 Standard</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.36</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S3 Standard storage (1 GB per month), S3 Stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>S3:metadata</td>\n",
       "      <td>Data Transfer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>5.40</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DT Inbound: Internet (0 TB per month), DT Outb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>S3:images</td>\n",
       "      <td>S3 Standard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.6500</td>\n",
       "      <td>1135.80</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S3 Standard storage (4 TB per month), PUT, COP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>S3:images</td>\n",
       "      <td>Data Transfer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>216.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DT Inbound: Internet (0 TB per month), DT Outb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NITELite_pipeline</td>\n",
       "      <td>US East (N. Virginia)</td>\n",
       "      <td>RDS:images</td>\n",
       "      <td>Amazon RDS for PostgreSQL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1027.4734</td>\n",
       "      <td>12329.68</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storage volume (General Purpose SSD (gp2)), St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group hierarchy                 Region        Description  \\\n",
       "0  NITELite_pipeline  US East (N. Virginia)  DynamoDB:metadata   \n",
       "1  NITELite_pipeline  US East (N. Virginia)  DynamoDB:metadata   \n",
       "2  NITELite_pipeline  US East (N. Virginia)  DynamoDB:metadata   \n",
       "3  NITELite_pipeline  US East (N. Virginia)  DynamoDB:metadata   \n",
       "4  NITELite_pipeline  US East (N. Virginia)       RDS:metadata   \n",
       "5  NITELite_pipeline  US East (N. Virginia)        S3:metadata   \n",
       "6  NITELite_pipeline  US East (N. Virginia)        S3:metadata   \n",
       "7  NITELite_pipeline  US East (N. Virginia)          S3:images   \n",
       "8  NITELite_pipeline  US East (N. Virginia)          S3:images   \n",
       "9  NITELite_pipeline  US East (N. Virginia)         RDS:images   \n",
       "\n",
       "                               Service   Upfront    Monthly  \\\n",
       "0          DynamoDB on-demand capacity  0.000000    13.1300   \n",
       "1          DynamoDB Backup and restore  0.000000     0.9000   \n",
       "2    DynamoDB Data export to Amazon S3  0.000000     0.4000   \n",
       "3  DynamoDB Data Import from Amazon S3  0.000000     0.3000   \n",
       "4            Amazon RDS for PostgreSQL  0.000000    23.2325   \n",
       "5                          S3 Standard  0.000715     0.0300   \n",
       "6                        Data Transfer  0.000000     0.4500   \n",
       "7                          S3 Standard  0.000000    94.6500   \n",
       "8                        Data Transfer  0.000000    18.0000   \n",
       "9            Amazon RDS for PostgreSQL  0.000000  1027.4734   \n",
       "\n",
       "   First 12 months total Currency  Status  \\\n",
       "0                 157.56      USD     NaN   \n",
       "1                  10.80      USD     NaN   \n",
       "2                   4.80      USD     NaN   \n",
       "3                   3.60      USD     NaN   \n",
       "4                 278.79      USD     NaN   \n",
       "5                   0.36      USD     NaN   \n",
       "6                   5.40      USD     NaN   \n",
       "7                1135.80      USD     NaN   \n",
       "8                 216.00      USD     NaN   \n",
       "9               12329.68      USD     NaN   \n",
       "\n",
       "                               Configuration summary  \n",
       "0  Table class (Standard), Average item size (all...  \n",
       "1  On-demand backup data storage (2 GB), Table da...  \n",
       "2  Full export to Amazon S3 (2 GB), Incremental e...  \n",
       "3  Uncompressed source file size for Import from ...  \n",
       "4  Storage volume (General Purpose SSD (gp2)), St...  \n",
       "5  S3 Standard storage (1 GB per month), S3 Stand...  \n",
       "6  DT Inbound: Internet (0 TB per month), DT Outb...  \n",
       "7  S3 Standard storage (4 TB per month), PUT, COP...  \n",
       "8  DT Inbound: Internet (0 TB per month), DT Outb...  \n",
       "9  Storage volume (General Purpose SSD (gp2)), St...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates = pd.read_csv('./NITELite_estimate.csv', header=5, skipfooter=2)\n",
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description\n",
       "DynamoDB:metadata      14.7300\n",
       "RDS:images           1027.4734\n",
       "RDS:metadata           23.2325\n",
       "S3:images             112.6500\n",
       "S3:metadata             0.4800\n",
       "Name: Monthly, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates.groupby('Description')['Monthly'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros/Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding images, it is cost-prohibitive to store the images on RDS, so storing the images on S3, where they are now, is the only real choice.\n",
    "The rest of the analysis will focus on the metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDS\n",
    "\n",
    "Pros:\n",
    "- Good SQL practice ;)\n",
    "\n",
    "Cons:\n",
    "- Requires an elaborate set-up\n",
    "- Most-expensive of the options if using a proxy. Not prohibitively expensive, but not free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DynamoDB\n",
    "\n",
    "Pros:\n",
    "- Fully on-demand usage.\n",
    "\n",
    "Cons:\n",
    "- Not prohibitively expensive, but not free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3\n",
    "\n",
    "Pros:\n",
    "- Compatible with CSV, the format researchers will expect.\n",
    "- Practically free.\n",
    "\n",
    "Cons:\n",
    "- Access *may* be more difficult than for RDS or DynamoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nitelite-pipeline-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
