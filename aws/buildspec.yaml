version: 0.2

# TODO: Currently running as root, if we change to non-root then change this
# run-as: Linux-user-name

env:
  shell: bash
        
phases:
  install:
    commands:
      # Install mountpoint
      - wget https://s3.amazonaws.com/mountpoint-s3-release/latest/x86_64/mount-s3.rpm
      - sudo yum -y install ./mount-s3.rpm
  pre_build:
    commands:
      # Pull the image from the registry. This is faster than building from
      # scratch, especially when cached
      - echo 'Pulling the Docker image...'
      - aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/i2m6n0b5
      - docker pull public.ecr.aws/i2m6n0b5/nitelite-pipeline:latest
      # Mount the S3 buckets
      - mkdir /data; mkdir /data/input; mkdir /data/output
      - mkdir /data/input/referenced_images; mount-s3 nitelite.referenced-images /data/input/referenced_images
      - mkdir /data/input/metadata; mount-s3 nitelite.metadata /data/input/metadata
      - mkdir /data/input/images; mount-s3 nitelite.images /data/input/images
      # If there's checkpointed output, retrieve it
      - ./aws/get_checkpoint.sh
      # DEBUG
      # # Run the test suite. test.sh: environment setup, pytest.sh: python tests
      # - echo 'Running tests...'
      # - mkdir /data/test_data; mkdir /data/test_data/input; mkdir /data/test_data/output
      # - mount-s3 nitelite.test-data /data/test_data/input --allow-overwrite --allow-delete
      # - ./test/test.sh -c ./night-horizons-mapmaker/configs/metadata.yaml -d /data/test_data -f ./aws/docker-compose.yaml
  build:
    commands:
      # Run the pipeline. We set the timeout to significantly below the max
      # allowed by AWS (480m = 8h), so that there's time to copy the data
      - timeout 10m ./bin/pipeline.sh -c ${CONFIG_FILEPATH} -d /data  -f ./aws/docker-compose.yaml --mount_code
  post_build:
    commands:
      # Check output
      - echo 'Output:'; ls -R /data/output
      # Set up name for the artifact in the destination bucket
      - BASENAME=$(basename ${CONFIG_FILEPATH})
      - DIR=${BASENAME%.*}
      - SUBDIR=${FLIGHT_ID}_$(date +%Y-%m-%d_%H-%M-%S)
      - echo "Artifacts will be stored in s3://nitelite.pipeline-output/$DIR/$SUBDIR"

artifacts:
  base-directory: /data/output
  files:
    - '**/*'
  discard-paths: no
  name: $DIR/$SUBDIR